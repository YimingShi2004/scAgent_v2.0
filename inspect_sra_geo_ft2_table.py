#!/usr/bin/env python3
"""
ä¸“é—¨æ£€æŸ¥ sra_geo_ft2 è¡¨ç»“æ„çš„è„šæœ¬
Inspect sra_geo_ft2 table structure and generate column mapping
"""

import sys
import os
import json
from typing import Dict, List, Any

# Add scAgent to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'scAgent'))

from scAgent.db.connect import get_connection
import psycopg2.extras

def inspect_sra_geo_ft2_table():
    """
    è¯¦ç»†æ£€æŸ¥ sra_geo_ft2 è¡¨çš„ç»“æ„å’Œå†…å®¹
    """
    print("=" * 70)
    print("æ£€æŸ¥ merged.sra_geo_ft2 è¡¨ç»“æ„")
    print("=" * 70)
    
    try:
        conn = get_connection()
        
        # 1. è·å–è¡¨çš„åŸºæœ¬ä¿¡æ¯
        with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cur.execute("""
                SELECT COUNT(*) as exists
                FROM information_schema.tables 
                WHERE table_schema = 'merged' AND table_name = 'sra_geo_ft2'
            """)
            table_exists = cur.fetchone()['exists']
            
            if not table_exists:
                print("âŒ è¡¨ merged.sra_geo_ft2 ä¸å­˜åœ¨!")
                return None
            
            print("âœ… è¡¨ merged.sra_geo_ft2 å­˜åœ¨")
            
            # è·å–è¡Œæ•°
            cur.execute('SELECT COUNT(*) as total_rows FROM "merged"."sra_geo_ft2"')
            total_rows = cur.fetchone()['total_rows']
            print(f"ğŸ“Š æ€»è¡Œæ•°: {total_rows:,}")
            
            # 2. è·å–æ‰€æœ‰åˆ—çš„è¯¦ç»†ä¿¡æ¯
            cur.execute("""
                SELECT 
                    column_name,
                    data_type,
                    is_nullable,
                    column_default,
                    character_maximum_length,
                    numeric_precision,
                    ordinal_position
                FROM information_schema.columns 
                WHERE table_schema = 'merged' AND table_name = 'sra_geo_ft2'
                ORDER BY ordinal_position
            """)
            
            columns = cur.fetchall()
            print(f"ğŸ“‹ æ€»åˆ—æ•°: {len(columns)}")
            print()
            
            # 3. æ˜¾ç¤ºæ‰€æœ‰åˆ—çš„ä¿¡æ¯
            print("åˆ—è¯¦ç»†ä¿¡æ¯:")
            print("-" * 70)
            print(f"{'åºå·':<4} {'åˆ—å':<25} {'æ•°æ®ç±»å‹':<15} {'å¯ç©º':<5} {'å­—ç¬¦é•¿åº¦':<8}")
            print("-" * 70)
            
            for col in columns:
                seq = col['ordinal_position']
                name = col['column_name']
                dtype = col['data_type']
                nullable = 'YES' if col['is_nullable'] == 'YES' else 'NO'
                max_len = col['character_maximum_length'] or '-'
                
                print(f"{seq:<4} {name:<25} {dtype:<15} {nullable:<5} {max_len:<8}")
            
            # 4. è¯†åˆ«å…³é”®åˆ—å¹¶åˆ†ç±»
            key_columns = categorize_columns([col['column_name'] for col in columns])
            
            print("\n" + "=" * 70)
            print("å…³é”®åˆ—åˆ†ç±»:")
            print("=" * 70)
            for category, cols in key_columns.items():
                if cols:
                    print(f"\nğŸ” {category.upper()} ({len(cols)} åˆ—):")
                    for col in cols:
                        print(f"   - {col}")
            
            # 5. è·å–æ ·æœ¬æ•°æ®
            print("\n" + "=" * 70)
            print("æ ·æœ¬æ•°æ®åˆ†æ (å‰3è¡Œ):")
            print("=" * 70)
            
            cur.execute('SELECT * FROM "merged"."sra_geo_ft2" LIMIT 3')
            sample_data = cur.fetchall()
            
            for i, row in enumerate(sample_data, 1):
                print(f"\nğŸ“„ æ ·æœ¬ {i}:")
                # æ˜¾ç¤ºå…³é”®å­—æ®µ
                key_fields = [
                    'run_accession', 'study_accession', 'sample_accession', 'experiment_accession',
                    'organism_ch1', 'organism', 'experiment_title', 'characteristics_ch1',
                    'study_title', 'library_strategy', 'instrument_model', 'platform'
                ]
                
                for field in key_fields:
                    if field in row:
                        value = row[field]
                        if value is not None:
                            if isinstance(value, str) and len(value) > 60:
                                value = value[:60] + "..."
                            print(f"   {field}: {value}")
                        else:
                            print(f"   {field}: NULL")
            
            # 6. ç”Ÿæˆåˆ—æ˜ å°„é…ç½®
            column_mapping = generate_column_mapping(columns)
            
            print("\n" + "=" * 70)
            print("ç”Ÿæˆçš„åˆ—æ˜ å°„é…ç½®:")
            print("=" * 70)
            print(json.dumps(column_mapping, indent=2, ensure_ascii=False))
            
            # 7. ä¿å­˜æ˜ å°„åˆ°æ–‡ä»¶
            with open('sra_geo_ft2_column_mapping.json', 'w', encoding='utf-8') as f:
                json.dump({
                    'table_info': {
                        'schema': 'merged',
                        'table': 'sra_geo_ft2',
                        'total_rows': total_rows,
                        'total_columns': len(columns)
                    },
                    'columns': [dict(col) for col in columns],
                    'column_mapping': column_mapping,
                    'key_columns': key_columns
                }, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nğŸ’¾ åˆ—æ˜ å°„ä¿¡æ¯å·²ä¿å­˜åˆ°: sra_geo_ft2_column_mapping.json")
            
            conn.close()
            return column_mapping
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        return None

def categorize_columns(column_names: List[str]) -> Dict[str, List[str]]:
    """
    æ ¹æ®åˆ—åç‰¹å¾å¯¹åˆ—è¿›è¡Œåˆ†ç±»
    """
    categories = {
        'identifiers': [],      # æ ‡è¯†ç¬¦åˆ—
        'organism_info': [],    # ç‰©ç§ä¿¡æ¯åˆ—
        'sample_info': [],      # æ ·æœ¬ä¿¡æ¯åˆ—
        'experiment_info': [],  # å®éªŒä¿¡æ¯åˆ—
        'sequencing_info': [],  # æµ‹åºä¿¡æ¯åˆ—
        'study_info': [],       # ç ”ç©¶ä¿¡æ¯åˆ—
        'quality_info': [],     # è´¨é‡ä¿¡æ¯åˆ—
        'date_info': [],        # æ—¥æœŸä¿¡æ¯åˆ—
        'location_info': [],    # ä½ç½®ä¿¡æ¯åˆ—
        'other': []             # å…¶ä»–åˆ—
    }
    
    # å®šä¹‰åˆ†ç±»è§„åˆ™
    patterns = {
        'identifiers': [
            'accession', 'id', 'identifier', 'gsm', 'srr', 'srx', 'srs', 'srp', 'gse', 'geo'
        ],
        'organism_info': [
            'organism', 'species', 'scientific_name', 'taxon', 'strain', 'isolate'
        ],
        'sample_info': [
            'sample', 'source', 'characteristics', 'tissue', 'cell', 'organ', 'body_part'
        ],
        'experiment_info': [
            'experiment', 'title', 'description', 'protocol', 'treatment', 'condition'
        ],
        'sequencing_info': [
            'library', 'platform', 'instrument', 'strategy', 'source', 'selection', 
            'layout', 'spots', 'bases', 'avgspotlen'
        ],
        'study_info': [
            'study', 'project', 'abstract', 'summary', 'publication', 'pubmed'
        ],
        'quality_info': [
            'quality', 'score', 'filter', 'pass', 'fail', 'qc'
        ],
        'date_info': [
            'date', 'time', 'created', 'updated', 'submitted', 'released'
        ],
        'location_info': [
            'country', 'location', 'geographic', 'region', 'center', 'lab'
        ]
    }
    
    # å¯¹æ¯ä¸ªåˆ—åè¿›è¡Œåˆ†ç±»
    for col_name in column_names:
        col_lower = col_name.lower()
        categorized = False
        
        for category, keywords in patterns.items():
            if any(keyword in col_lower for keyword in keywords):
                categories[category].append(col_name)
                categorized = True
                break
        
        if not categorized:
            categories['other'].append(col_name)
    
    return categories

def generate_column_mapping(columns) -> Dict[str, str]:
    """
    ä¸º sc-eQTL åˆ†æç”Ÿæˆå…³é”®åˆ—çš„æ˜ å°„
    """
    column_names = [col['column_name'] for col in columns]
    
    # å®šä¹‰éœ€è¦æ˜ å°„çš„å…³é”®å­—æ®µ
    mapping_rules = {
        # æ ‡è¯†ç¬¦å­—æ®µ
        'run_accession': ['run_accession', 'sra_run_accession', 'run_id'],
        'study_accession': ['study_accession', 'sra_study_accession', 'study_id', 'project_accession'],
        'sample_accession': ['sample_accession', 'sra_sample_accession', 'sample_id'],
        'experiment_accession': ['experiment_accession', 'sra_experiment_accession', 'experiment_id'],
        'geo_accession': ['geo_accession', 'gse', 'geo_series'],
        
        # ç‰©ç§ç›¸å…³å­—æ®µ
        'organism': ['organism', 'species'],
        'organism_ch1': ['organism_ch1', 'organism_1'],
        'scientific_name': ['scientific_name', 'organism_name'],
        'taxon_id': ['taxon_id', 'tax_id', 'taxonomy_id'],
        
        # å®éªŒä¿¡æ¯å­—æ®µ
        'experiment_title': ['experiment_title', 'title', 'gsm_title'],
        'study_title': ['study_title', 'project_title'],
        'study_abstract': ['study_abstract', 'abstract', 'summary'],
        
        # æ ·æœ¬ä¿¡æ¯å­—æ®µ
        'sample_title': ['sample_title', 'sample_name'],
        'source_name': ['source_name', 'source'],
        'characteristics_ch1': ['characteristics_ch1', 'characteristics', 'sample_characteristics'],
        'tissue': ['tissue', 'tissue_type', 'organ'],
        
        # æµ‹åºä¿¡æ¯å­—æ®µ
        'library_strategy': ['library_strategy', 'strategy'],
        'library_source': ['library_source', 'source'],
        'library_selection': ['library_selection', 'selection'],
        'library_layout': ['library_layout', 'layout'],
        'platform': ['platform', 'sequencing_platform'],
        'instrument_model': ['instrument_model', 'instrument', 'machine'],
        
        # æ•°æ®é‡å­—æ®µ
        'spots': ['spots', 'spot_count', 'read_count'],
        'bases': ['bases', 'base_count'],
        'avgspotlen': ['avgspotlen', 'avg_spot_length', 'read_length'],
        
        # æ—¥æœŸå­—æ®µ
        'submission_date': ['submission_date', 'submitted_date', 'create_date'],
        'publication_date': ['publication_date', 'release_date', 'public_date'],
        
        # å…¶ä»–é‡è¦å­—æ®µ
        'bioproject': ['bioproject', 'project_id'],
        'biosample': ['biosample', 'sample_id'],
        'center_name': ['center_name', 'center', 'submitter'],
        'description': ['description', 'desc']
    }
    
    # æ‰§è¡Œæ˜ å°„
    column_mapping = {}
    for logical_name, possible_names in mapping_rules.items():
        for possible_name in possible_names:
            # ç²¾ç¡®åŒ¹é…
            if possible_name in column_names:
                column_mapping[logical_name] = possible_name
                break
            # æ¨¡ç³ŠåŒ¹é…
            for col_name in column_names:
                if possible_name.lower() in col_name.lower():
                    column_mapping[logical_name] = col_name
                    break
            if logical_name in column_mapping:
                break
    
    return column_mapping

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” SRA-GEO-FT2 è¡¨ç»“æ„æ£€æŸ¥å·¥å…·")
    
    mapping = inspect_sra_geo_ft2_table()
    
    if mapping:
        print("\nâœ… æ£€æŸ¥å®Œæˆï¼å¯ä»¥ä½¿ç”¨ç”Ÿæˆçš„åˆ—æ˜ å°„æ›´æ–°ä¼˜åŒ–å™¨ã€‚")
        return 0
    else:
        print("\nâŒ æ£€æŸ¥å¤±è´¥ï¼")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 